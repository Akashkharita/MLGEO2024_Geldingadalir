{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data Download Notebook\n",
    "\n",
    "*Important Note:* This notebook runs using a different environment than this project's computational notebook. ObsPy is required, along with numpy and matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zali et al. 2024 pulls horizontal seismic data from a single horizontal component from a single station, demeaned and detrended but not converted from instrument response. The data is pulled from March 12 to June 24, ~104 days, beginning 7 days before the Geldingadalir eruption began. The data is also downsampled to the minimum sampling rate necessary to observe the local volcanic tremor.\n",
    "\n",
    "------------------\n",
    "\n",
    "This notebook will download 100 days of data, beginning May 16 and ending August 24, from sensor AV.GSTD of the Alaska Volcano Observatory's network, located on the Great Sitkin Volcano. The Great Sitkin had an explosive eruption at 05:04 (UTC) May 26, 2021, followed by lava flow in mid-July https://avo.alaska.edu/eruption/great-sitkin-2021-05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import UTCDateTime as utc\n",
    "from obspy.clients.fdsn import Client\n",
    "client = Client('IRIS')\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(st, buffer, freq, max_target_frequency): #freq is the original sampling frequency\n",
    "    st.merge(fill_value='interpolate')\n",
    "    tr = st[0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The seismic data is downloaded from the IRIS/Earthscope Database using ObsPy. The data downloads as a trace, an array of data with attached metadata, which is then packaged into a stream, which can contain multiple traces. The daily seismic data records are then saved as mseed files, which preserve this data+metadata structure, but requires ObsPy or other specialized software to open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "mkdir: data/raw: File exists\n"
     ]
    }
   ],
   "source": [
    "#creating variables to download data\n",
    "starttime = utc('2021-05-16T00:00:00')\n",
    "endtime = starttime + 100 * (60*60*24)\n",
    "\n",
    "#also add a buffer to both ends to chop off once the data has been filtered\n",
    "#and downsampled, kind of arbitrary length, 5% of a day (default ObsPy taper length)\n",
    "buffer = 60*60*24*0.05 #seconds\n",
    "\n",
    "net = 'AV'\n",
    "sta = 'GSTD'\n",
    "loc = '*' #wildcard, generally don't care about location code\n",
    "cha = 'BHN' #horizontal component, as used in Zali et al\n",
    "\n",
    "#create folder for numpy streams to go into and initialize filepath\n",
    "! mkdir data\n",
    "! mkdir data/raw\n",
    "filepath = os.getcwd() + '/data/raw/'\n",
    "\n",
    "#create arrays to save dates\n",
    "dates = np.array([])\n",
    "\n",
    "#download the data piecemeal, here by day\n",
    "for day in range(100):\n",
    "    tr_length = 24*60*60\n",
    "\n",
    "    #actually downloading\n",
    "    st = client.get_waveforms(network=net,\n",
    "                     station=sta,\n",
    "                     location=loc,\n",
    "                     channel=cha,\n",
    "                     starttime=starttime-buffer,\n",
    "                     endtime=starttime+buffer+tr_length)\n",
    "\n",
    "    #instrument sampling rate (hz)\n",
    "    freq = st[0].stats.sampling_rate\n",
    "\n",
    "    #merge traces within stream, linearly interpolating any gaps\n",
    "    st.merge(fill_value='interpolate')\n",
    "    \n",
    "    #generate filename, day number in front for convenience of reading in\n",
    "    name = str(day+1)+'_sitkin.mseed'\n",
    "    \n",
    "    #save data as mseed, standard for storing seismic data. Preserves metadata and time series info\n",
    "    st.write(filepath+name, format='MSEED')\n",
    "\n",
    "    #adding date\n",
    "    dates = np.append(dates, starttime.date)\n",
    "\n",
    "    starttime += tr_length\n",
    "\n",
    "#save dates list for future use\n",
    "np.save(filepath+'date_list.csv', dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "array",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
